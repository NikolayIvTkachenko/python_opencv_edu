# Принципы работы детекции лиц
# Современные алгоритмы детекции лиц основаны на методах глубокого обучения и используют сверточные нейронные
# сети (CNN) для анализа изображений. Процесс детекции можно разделить на три основных этапа:
#
# 1. Предобработка изображения
# Преобразование цветового пространства: Изображение переводится в определённый формат (обычно RGB или BGR),
# что необходимо для корректной работы модели.
# Масштабирование и нормализация: Изображение может быть изменено до определённого размера, а значения пикселей
# нормализованы для ускорения и повышения эффективности обработки.
# Фильтрация шума: Применение фильтров для уменьшения шума и повышения качества изображения.
# 2. Модель детекции лиц
# Использование предобученных моделей: Модели, такие как MediaPipe Face Detection, обучены на больших наборах
# данных и способны точно определять положение лиц и их ключевых точек.
# Анализ изображения: Модель сканирует изображение, выделяя области, где с высокой вероятностью присутствуют лица.
# Определение ключевых точек: Помимо обнаружения лиц, модель может идентифицировать важные точки, такие как глаза,
# нос и рот.
# 3. Постобработка результатов
# Преобразование координат: Нормализованные координаты, полученные от модели, преобразуются в пиксельные координаты
# исходного изображения.
# Визуализация результатов: Нанесение на изображение ограничивающих рамок, ключевых точек или других визуальных
# элементов для отображения результатов детекции.
# Фильтрация и оптимизация: Возможна дополнительная обработка для устранения ложных срабатываний и улучшения точности.
# MediaPipe Face Detection
# MediaPipe — это кроссплатформенная фреймворк от Google, предназначенная для построения конвейеров обработки мультимедийных
# данных. Она предоставляет готовые решения для различных задач компьютерного зрения, включая детекцию лиц.
#
# Преимущества использования MediaPipe:
# Высокая производительность: Оптимизирован для работы в реальном времени даже на устройствах с ограниченными ресурсами.
# Точность: Использует передовые модели глубокого обучения для обеспечения высокой точности.
# Удобство интеграции: Легко интегрируется с популярными библиотеками, такими как OpenCV, и поддерживает
# различные языки программирования.
# Реализация: детекция лиц с использованием MediaPipe
# Ниже представлен пример реализации детекции лиц с использованием MediaPipe и OpenCV

# https://ai.google.dev/edge/mediapipe/solutions/vision/face_detector?hl=ru
#
# Инициализация MediaPipe:
# mp_face_detection.FaceDetection: Создает объект детектора лиц.
# model_selection=0: Выбор модели; 0 для коротких расстояний, 1 для длинных.
# min_detection_confidence=0.5: Минимальная уверенность детекции, значения от 0 до 1.
# Обработка видеопотока:
# Чтение кадров из веб-камеры.
# Преобразование цветового пространства для корректной работы модели.
# Детекция лиц на каждом кадре.
# Визуализация результатов:
# Использование mp_drawing.draw_detection или ручной разбор и рисование всех точек для отображения ограничивающих
# рамок и ключевых точек на лицах.
# Отображение обработанного кадра в окне.
# Настройки и улучшения
# Регулировка чувствительности: Изменяя параметр min_detection_confidence, можно управлять чувствительностью детекции.
# Выбор модели: Параметр model_selection позволяет выбирать между моделью для ближних (0) и дальних (1) расстояний.
# Обработка нескольких лиц: Алгоритм автоматически обнаруживает и обрабатывает несколько лиц в кадре.

import cv2
import mediapipe as mp

# Инициализация модулей MediaPipe
mp_face_detection = mp.solutions.face_detection
mp_drawing = mp.solutions.drawing_utils
face_detection = mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5)
# Открытие видеопотока с веб-камеры
cap = cv2.VideoCapture(0)

# Проверка открытия камеры
if not cap.isOpened():
    print("Ошибка: Не удалось открыть камеру.")
    exit()

print("Нажмите 'Esc' для выхода.")

while True:
    ret, frame = cap.read()
    if not ret:
        print("Ошибка: Не удалось получить кадр.")
        break

    # Отзеркаливание изображения для удобства
    frame = cv2.flip(frame, 1)

    # Преобразование изображения в RGB
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # Детекция лиц
    results = face_detection.process(frame_rgb)

    # Обработка результатов детекции
    if results.detections:
        for detection in results.detections:
            # Рисование ограничивающей рамки и ключевых точек стандартным методом
            # mp_drawing.draw_detection(frame, detection)

            # Рисование ограничивающей рамки и ключевых точек с разбором всех компонентов
            # Получение размеров изображения
            image_height, image_width, _ = frame.shape

            # Извлечение координат ограничивающей рамки
            bbox = detection.location_data.relative_bounding_box
            x_min = int(bbox.xmin * image_width)
            y_min = int(bbox.ymin * image_height)
            box_width = int(bbox.width * image_width)
            box_height = int(bbox.height * image_height)

            # Рисование ограничивающей рамки
            cv2.rectangle(frame, (x_min, y_min), (x_min + box_width, y_min + box_height), (0, 255, 0), 2)

            # Рисование ключевых точек
            for keypoint in detection.location_data.relative_keypoints:
                keypoint_x = int(keypoint.x * image_width)
                keypoint_y = int(keypoint.y * image_height)
                cv2.circle(frame, (keypoint_x, keypoint_y), 5, (0, 0, 255), -1)

            # Отображение вероятности детекции
            confidence_score = int(detection.score[0] * 100)
            cv2.putText(frame, f'{confidence_score}%', (x_min, y_min - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)

    # Отображение изображения
    cv2.imshow('Face detector', frame)

    # Выход по нажатию 'Esc'
    if cv2.waitKey(20) == 27:
        break

# Освобождение ресурсов
cap.release()
cv2.destroyAllWindows()