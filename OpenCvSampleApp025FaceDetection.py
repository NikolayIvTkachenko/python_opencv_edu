# Наложение графических объектов на лицо
# В данном разделе мы рассматриваем процесс автоматизации наложения графических объектов на лицо. Цель состоит в
# том, чтобы разработать систему, которая автоматически накладывает очки на изображение лица, учитывая положение,
# масштаб и угол поворота лица в реальном времени.
#
# Подготовка данных
# Необходимые изображения (скачать):
# Изображение с очками (например, файл glasses.png).
# Изображение лица (например, файл face.png) или
# Изображение с камеры
# Точки сопоставления:
# Ключевые точки лица (глаза, нос и т.д.) будут извлекаться с помощью MediaPipe.
# Ключевые точки очков будут задаваться заранее
# Алгоритм работы
# Детекция ключевых точек лица:
#
# Используем MediaPipe для обнаружения ключевых точек на изображении лица.
# Выбираем ключевые точки для позиционирования очков (например, центры левого и правого глаза).
# Позиционирование очков:
#
# Определяем масштаб и угол поворота очков, основываясь на расстоянии и наклоне между глазами.
# Преобразуем изображение очков с помощью матричных операций (масштабирование, поворот).
# Наложение очков на лицо:
#
# "Надеваем" очки на лицо, используя маску прозрачности для корректного наложения.
# Определяем масштаб и угол поворота

import cv2
import mediapipe as mp
import numpy as np

# Инициализация модулей MediaPipe
mp_face_detection = mp.solutions.face_detection
mp_drawing = mp.solutions.drawing_utils
face_detection = mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5)

# Открытие видеопотока с веб-камеры
cap = cv2.VideoCapture(0)

# Проверка открытия камеры
if not cap.isOpened():
    print("Ошибка: Не удалось открыть камеру.")
    exit()

print("Нажмите 'Esc' для выхода.")

while True:
    ret, frame = cap.read()
    if not ret:
        print("Ошибка: Не удалось получить кадр.")
        break

    # Отзеркаливание изображения для удобства
    frame = cv2.flip(frame, 1)

    # Преобразование изображения в RGB
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # Детекция лиц
    results = face_detection.process(frame_rgb)

    # Обработка результатов детекции
    if results.detections:
        for detection in results.detections:
            # Извлечение размеров изображения
            image_height, image_width, _ = frame.shape

            # Извлечение координат точек 4 и 5 (левое и правое ухо)
            try:
                left_ear = detection.location_data.relative_keypoints[4]
                right_ear = detection.location_data.relative_keypoints[5]

                # Преобразование относительных координат в пиксельные
                left_ear_x, left_ear_y = int(left_ear.x * image_width), int(left_ear.y * image_height)
                right_ear_x, right_ear_y = int(right_ear.x * image_width), int(right_ear.y * image_height)

                # Рисование точек 4 и 5
                cv2.circle(frame, (left_ear_x, left_ear_y), 5, (0, 255, 255), -1)  # Левое ухо - желтое
                cv2.circle(frame, (right_ear_x, right_ear_y), 5, (255, 255, 0), -1)  # Правое ухо - голубое

                # Рисование линии между ушами
                cv2.line(frame, (left_ear_x, left_ear_y), (right_ear_x, right_ear_y), (0, 0, 255), 2)

                # Вычисление угла между ушами
                dx = right_ear_x - left_ear_x
                dy = right_ear_y - left_ear_y
                angle = int(np.degrees(np.arctan2(dy, dx)))
                cv2.putText(frame, f'Angle: {angle} deg', (left_ear_x, left_ear_y - 20),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

            except IndexError:
                print("Не удалось извлечь ключевые точки 4 и 5.")

            # Отображение вероятности детекции
            confidence_score = int(detection.score[0] * 100)
            cv2.putText(frame, f'{confidence_score}%', (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)

    # Отображение изображения
    cv2.imshow('Angle detector', frame)

    # Выход по нажатию 'Esc'
    if cv2.waitKey(20) == 27:
        break

# Освобождение ресурсов
cap.release()
cv2.destroyAllWindows()

# mp_face_detection.FaceDetection: создает объект для детекции лиц.
# model_selection=0: выбирает модель для коротких расстояний (0 — для расстояний до 2 метров).
# min_detection_confidence=0.5: минимальная вероятность детекции лица.
# Основной цикл обработки кадров:
#
# Чтение кадра:
#
# ret, frame = cap.read(): считывает текущий кадр из видеопотока.
# Предобработка кадра:
#
# Отзеркаливание кадра: frame = cv2.flip(frame, 1) делает изображение зеркальным по горизонтали для более естественного взаимодействия.
# Преобразование в RGB: frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), поскольку MediaPipe работает с RGB-изображениями.
# Детекция лица:
#
# results = face_detection.process(frame_rgb): выполняет детекцию лица на текущем кадре.
# Если лица обнаружены (if results.detections:), продолжается обработка.
# Обработка результатов детекции:
#
# Извлечение размеров изображения: image_height, image_width, _ = frame.shape для преобразования относительных координат в пиксельные значения.
#
# Извлечение ключевых точек (левое и правое ухо):
#
# Точки 4 и 5 в MediaPipe Face Detection соответствуют левому и правому уху.
# Преобразование координат: умножаем относительные координаты на ширину и высоту изображения для получения пиксельных координат.
# Визуализация ключевых точек:
#
# Рисование кругов: cv2.circle отображает ключевые точки на изображении.
# Рисование линии между ушами: cv2.line соединяет точки для визуализации наклона головы.
# Вычисление угла поворота головы:
# В данном фрагменте кода мы вычисляем угол между ушами пользователя на изображении, чтобы определить наклон головы.
# Это важно для корректного позиционирования и поворота графических объектов (например, очков) при наложении на лицо.


# dx = right_ear_x - left_ear_x
# dy = right_ear_y - left_ear_y
# angle = int(np.degrees(np.arctan2(dy, dx)))
# cv2.putText(frame, f'Angle: {angle} deg', (left_ear_x, left_ear_y - 20),
#             cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

# Разница
# координат: dx
# и
# dy — разницы
# по
# оси
# X
# и
# Y
# между
# ушами.
#
# dx: горизонтальное
# расстояние
# между
# правым
# и
# левым
# ухом.
# Это
# разница
# по
# оси
# X
# между
# координатами
# правого
# и
# левого
# уха.
# Положительное
# значение
# dx
# указывает, что
# правое
# ухо
# находится
# правее
# левого.
# dy: вертикальное
# расстояние
# между
# правым
# и
# левым
# ухом.
# Это
# разница
# по
# оси
# Y
# между
# координатами
# правого
# и
# левого
# уха.
# Положительное
# значение
# dy
# указывает, что
# правое
# ухо
# ниже
# левого.
# Угол
# наклона: angle = int(np.degrees(np.arctan2(dy, dx)))
# вычисляет
# угол
# в
# градусах.
#
# np.arctan2(dy, dx):
# Функция
# arctan2
# из
# библиотеки
# NumPy
# вычисляет
# арктангенс
# двух
# переменных
# dy
# и
# dx.
# Возвращает
# угол
# θ
# в
# радианах
# между
# положительной
# осью
# X
# и
# вектором(dx, dy).
# Учитывает
# знаки
# dx
# и
# dy, что
# позволяет
# определить
# правильный
# квадрант
# угла.
# Диапазон
# значений: от - π
# до
# π
# радиан(от - 180° до
# 180°).
# np.degrees():
# Преобразует
# угол
# из
# радиан
# в
# градусы
# для
# удобства
# восприятия.
# int():
# Преобразует
# результат
# в
# целое
# число
# для
# отображения
# без
# дробной
# части.
# Таким
# образом, переменная
# angle
# содержит
# угол
# в
# градусах, характеризующий
# наклон
# головы
# пользователя.
#
# Отображение
# угла: cv2.putText
# выводит
# угол
# на
# изображении.
# Обработка
# исключений:
#
# Если
# ключевые
# точки
# не
# обнаружены, выводится
# сообщение
# об
# ошибке.
# Отображение
# вероятности
# детекции
# лица:
#
# confidence_score: вероятность, с
# которой
# модель
# обнаружила
# лицо.
# Вывод
# на
# изображение: отображение
# процента
# вероятности
# в
# верхнем
# левом
# углу.

# Отображение результата:
#
# cv2.imshow('Angle detector', frame): показывает текущий кадр с наложенными графическими элементами.
# Выход из цикла:
#
# Если пользователь нажимает клавишу 'Esc', цикл прерывается.
# Освобождение ресурсов:
#
# cap.release(): освобождает видеопоток.
# cv2.destroyAllWindows(): закрывает все окна OpenCV.
# Теперь, когда мы можем детектировать ключевые точки лица и вычислять масштаб и угол поворота, следующий
# шаг — потренироваться в полученных навыках и двинуться дальше, к совмещению изображений.