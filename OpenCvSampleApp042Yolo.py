# Структура данных на выходе из модели YOLOv11
# Модели YOLO (You Only Look Once) предназначены для решения задач детекции
# объектов на изображениях в реальном времени. YOLOv8 представляет собой одну
# из самых последних версий модели, и, как и предыдущие версии, она производит детекцию объектов, выделяя их
# с помощью ограничивающих рамок (bounding boxes), а также предоставляя информацию о классе объекта, вероятности
# классификации и других характеристиках.
#
# В этой статье мы детально рассмотрим структуру данных, которую возвращает модель YOLOv8 в процессе
# обработки изображения. Для этого будет проанализирован объект results, который является основным выводом
# модели после обработки изображения. Мы подробно разберем такие
# составляющие, как boxes, classes, names, и другие атрибуты, которые являются результатами работы модели.
#
# from ultralytics import YOLO
# from google.colab.patches import cv2_imshow
# import cv2
#
# # Загрузка модели
# model = YOLO("yolo11x.pt")
#
# # Детекция объектов на изображении
# results = model(path + "street.png", save=True)
#
# print(results)

# 1. Объект results
# Объект results
# После того как модель YOLOv8 выполнит детекцию на изображении, она возвращает объект, содержащий несколько ключевых
# атрибутов. Этот объект включает информацию о:
#
# boxes — объект типа ultralytics.engine.results.Boxes, который содержит координаты рамок, предсказанные моделью для
# каждого объекта.
# names — словарь, содержащий соответствие индексов классов с их именами (например, 'person', 'car', 'dog' и т.д.).
# orig_img — оригинальное изображение, которое использовалось для обработки.
# shape — размер изображения в пикселях.
# speed — информация о времени выполнения различных этапов процесса, включая препроцессинг, инференс и постобработку.

# [ultralytics.engine.results.Results object with attributes:
#
# boxes: ultralytics.engine.results.Boxes object
# keypoints: None
# masks: None
# names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}
# obb: None
# orig_img: array([[[121, 130, 114],
#         [ 97, 103,  90],
#         [107, 112,  99],
#         ...,
#         [140, 130, 124]]], dtype=uint8)
# orig_shape: (602, 1045)
# path: '/content/street.png'
# probs: None
# save_dir: 'runs/detect/predict'
# speed: {'preprocess': 16.950607299804688, 'inference': 2945.978879928589, 'postprocess': 43.80393028259277}]

#
# 2. Атрибут boxes
# Атрибут boxes является объектом класса Boxes и представляет собой информацию о предсказанных объектах на
# изображении. Он включает следующие важные данные:
#
# cls — представляет собой тензор с метками классов, который отображает тип объекта в
# каждой рамке. Например, для человека класс может быть равен 0, для велосипеда — 1 и
# так далее. Эти значения являются индексами в словаре, который связывает числовые метки с наименованиями классов.
# conf — это тензор уверенности модели в предсказаниях для каждой рамки. Он варьируется
# от 0 до 1, где 1 означает, что модель очень уверена в своем предсказании, а значения, близкие к
# 0, говорят о низкой уверенности.
# data — данные о координатах ограничивающих рамок объектов. Это 2D-данные, где каждая
# рамка представлена четырьмя значениями: x1, y1, x2, y2, которые определяют координаты
# верхнего левого и нижнего правого углов рамки.

# ultralytics.engine.results.Boxes object with attributes:
#
# cls: tensor([2., 5., 2., 2., 7., 2., 2., 0., 2., 2., 2., 2.])
# conf: tensor([0.9303, 0.9204, 0.9200, 0.9074, 0.8825, 0.8709, 0.7166, 0.7014, 0.7007, 0.5697, 0.3362, 0.2956])
# data: tensor([[7.1199e+02, 3.6472e+02, 8.2931e+02, 4.2518e+02, 9.3026e-01, 2.0000e+00],
#         [2.8016e+02, 3.1607e+02, 4.1574e+02, 4.3900e+02, 9.2036e-01, 5.0000e+00],
#         [8.6357e+02, 3.6395e+02, 1.0279e+03, 4.4391e+02, 9.1997e-01, 2.0000e+00],
#         [3.9431e+01, 3.6593e+02, 1.7398e+02, 4.6096e+02, 9.0739e-01, 2.0000e+00],
#         [4.4449e+02, 3.4252e+02, 4.9053e+02, 3.9799e+02, 8.8250e-01, 7.0000e+00],
#         [5.9699e+02, 3.7024e+02, 6.6619e+02, 4.1224e+02, 8.7090e-01, 2.0000e+00],
#         [1.7353e+02, 3.6416e+02, 2.2013e+02, 4.3222e+02, 7.1658e-01, 2.0000e+00],
#         [5.6486e+02, 3.6166e+02, 5.7724e+02, 3.9283e+02, 7.0135e-01, 0.0000e+00],
#         [1.1009e+02, 3.6172e+02, 1.8258e+02, 4.4143e+02, 7.0073e-01, 2.0000e+00],
#         [4.2031e+02, 3.7038e+02, 4.4727e+02, 3.9583e+02, 5.6972e-01, 2.0000e+00],
#         [2.1527e+02, 3.6643e+02, 2.3136e+02, 3.9716e+02, 3.3623e-01, 2.0000e+00],
#         [2.6451e+02, 3.7864e+02, 2.7303e+02, 3.8801e+02, 2.9560e-01, 2.0000e+00]])
# id: None
# is_track: False
# orig_shape: (602, 1045)
# shape: torch.Size([12, 6])
# xywh: tensor([[770.6511, 394.9487, 117.3133,  60.4575],
#         [347.9512, 377.5319, 135.5859, 122.9305],
#         [945.7329, 403.9305, 164.3245,  79.9545],
#         [106.7051, 413.4434, 134.5486,  95.0329],
#         [467.5114, 370.2538,  46.0455,  55.4738],
#         [631.5903, 391.2413,  69.1972,  42.0067],
#         [196.8332, 398.1916,  46.6026,  68.0537],
#         [571.0499, 377.2472,  12.3858,  31.1729],
#         [146.3324, 401.5777,  72.4924,  79.7136],
#         [433.7872, 383.1031,  26.9604,  25.4481],
#         [223.3155, 381.7947,  16.0822,  30.7350],
#         [268.7695, 383.3240,   8.5131,   9.3646]])
# xywhn: tensor([[0.7375, 0.6561, 0.1123, 0.1004],
#         [0.3330, 0.6271, 0.1297, 0.2042],
#         [0.9050, 0.6710, 0.1572, 0.1328],
#         [0.1021, 0.6868, 0.1288, 0.1579],
#         [0.4474, 0.6150, 0.0441, 0.0921],
#         [0.6044, 0.6499, 0.0662, 0.0698],
#         [0.1884, 0.6614, 0.0446, 0.1130],
#         [0.5465, 0.6267, 0.0119, 0.0518],
#         [0.1400, 0.6671, 0.0694, 0.1324],
#         [0.4151, 0.6364, 0.0258, 0.0423],
#         [0.2137, 0.6342, 0.0154, 0.0511],
#         [0.2572, 0.6368, 0.0081, 0.0156]])
# xyxy: tensor([[ 711.9944,  364.7200,  829.3077,  425.1775],
#         [ 280.1583,  316.0666,  415.7442,  438.9971],
#         [ 863.5707,  363.9532, 1027.8951,  443.9077],
#         [  39.4308,  365.9270,  173.9795,  460.9599],
#         [ 444.4887,  342.5170,  490.5342,  397.9907],
#         [ 596.9917,  370.2379,  666.1889,  412.2447],
#         [ 173.5319,  364.1647,  220.1345,  432.2185],
#         [ 564.8570,  361.6608,  577.2428,  392.8336],
#         [ 110.0862,  361.7209,  182.5786,  441.4345],
#         [ 420.3070,  370.3791,  447.2675,  395.8272],
#         [ 215.2744,  366.4272,  231.3566,  397.1622],
#         [ 264.5130,  378.6417,  273.0261,  388.0063]])
# xyxyn: tensor([[0.6813, 0.6058, 0.7936, 0.7063],
#         [0.2681, 0.5250, 0.3978, 0.7292],
#         [0.8264, 0.6046, 0.9836, 0.7374],
#         [0.0377, 0.6079, 0.1665, 0.7657],
#         [0.4253, 0.5690, 0.4694, 0.6611],
#         [0.5713, 0.6150, 0.6375, 0.6848],
#         [0.1661, 0.6049, 0.2107, 0.7180],
#         [0.5405, 0.6008, 0.5524, 0.6525],
#         [0.1053, 0.6009, 0.1747, 0.7333],
#         [0.4022, 0.6152, 0.4280, 0.6575],
#         [0.2060, 0.6087, 0.2214, 0.6597],
#         [0.2531, 0.6290, 0.2613, 0.6445]])


#
# cls — класс каждого предсказанного объекта, представленный как тензор, содержащий индексы классов для всех обнаруженных
# объектов (например, tensor([2., 5., 2., ...])).
# conf — вероятность того, что обнаруженный объект соответствует предсказанному классу, представлена как тензор
# с довериями (например, tensor([0.9303, 0.9204, ...])).
# data — тензор с данными, содержащий координаты ограничивающих рамок (bounding boxes), а также информацию о классе
# и уверенности. Каждая строка представляет собой [x1, y1, x2, y2, confidence, class_id], где:
# x1, y1, x2, y2 — координаты верхнего левого и нижнего правого углов рамки.
# confidence — вероятность того, что объект находится в рамке.
# class_id — индекс класса, который был предсказан для данного объекта.
# tensor([[711.9944, 364.7200, 829.3077, 425.1775, 0.9303, 2.0000],  # Координаты объекта с высоким доверием
#         [280.1583, 316.0666, 415.7442, 438.9971, 0.9204, 5.0000],  # Другой объект с меньшим доверием
#         ...])

# xywh — координаты ограничивающих рамок в формате «x, y, ширина, высота». Это полезный формат для
# большинства задач, таких как передача данных в нейронные сети, где объект необходимо представлять с
# указанием не только позиции (x, y), но и размера (ширина, высота) в формате[center_x, center_y, width, height], где:

# center_x, center_y — координаты центра рамки.
# width, height — размеры рамки
# tensor([[770.6511, 394.9487, 117.3133, 60.4575],
#         [347.9512, 377.5319, 135.5859, 122.9305],
#         ...])
# xyxy — тензор с координатами ограничивающих рамок в формате [x1, y1, x2, y2], которые можно использовать для
# рисования рамок на изображении.
#
# tensor([[711.9944, 364.7200, 829.3077, 425.1775],
#         [280.1583, 316.0666, 415.7442, 438.9971],
#         ...])
#
# xyxyn — нормализованные координаты рамок, которые измеряются относительно ширины и высоты изображения.
# Эти значения могут быть полезны, если необходимо масштабировать данные для различных размеров изображений.
#
# tensor([[0.6813, 0.6058, 0.7936, 0.7063],
#         [0.2681, 0.5250, 0.3978, 0.7292],
#         ...])
#
# 3. Прочие атрибуты
# names — словарь, в котором каждый индекс класса (например, 0, 1, 2) соответствует строковому имени объекта
# (например, 'person', 'car', 'dog').
# names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', ...}
# conf — вероятность, с которой модель предсказала каждый класс для объекта. Эти значения обычно используются
# для фильтрации предсказаний, например, при игнорировании объектов с низким уровнем уверенности (например, меньше 0.5).
# 4. Пример работы с результатами
# После выполнения модели на изображении, данные, полученные из объекта results, могут быть использованы для
# дальнейшей обработки, таких как рисование рамок, отображение классов, создание текстовых файлов с результатами,
# а также сохранение обработанных изображений.

#
# Детекция на изображении
# Для успешного внедрения YOLO в прикладные проекты необходимо не только уметь запускать модель, но и
# правильно интерпретировать её результаты, визуализировать обнаруженные объекты и сохранять информацию для
# последующего анализа. Без корректной обработки выходных данных любая высокоточная модель будет малоэффективна,
# так как конечная цель большинства приложений — автоматически реагировать на обнаруженные объекты или предоставлять
# пользователю удобную обратную связь в понятном виде.
#
# В этом уроке мы рассмотрим функцию process_image, которая наглядно демонстрирует практический цикл детекции
# объектов: чтение входного файла, обращение к модели YOLOv11 для получения результатов, интерпретация выходных
# данных, визуальная разметка сцены и сохранение полученных данных для дальнейшего использования. Такой подход
# позволяет организовать весь процесс детекции в компактном, но при этом наглядном и гибком виде, легко интегрируя
# его в более крупные системы или последующие шаги анализа.

from ultralytics import YOLO
import cv2
import numpy as np
import os

# Загрузка модели YOLOv11
model = YOLO('yolo11n.pt')

# Список цветов для различных классов
colors = [
    (255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (0, 255, 255),
    (255, 0, 255), (192, 192, 192), (128, 128, 128), (128, 0, 0), (128, 128, 0),
    (0, 128, 0), (128, 0, 128), (0, 128, 128), (0, 0, 128), (72, 61, 139),
    (47, 79, 79), (47, 79, 47), (0, 206, 209), (148, 0, 211), (255, 20, 147)
]


# Функция для обработки изображения
def process_image(image_path):
    # Загрузка изображения
    image = cv2.imread(image_path)
    results = model(image)[0]

    # Получение оригинального изображения и результатов
    image = results.orig_img
    classes_names = results.names
    classes = results.boxes.cls.cpu().numpy()
    boxes = results.boxes.xyxy.cpu().numpy().astype(np.int32)

    # Подготовка словаря для группировки результатов по классам
    grouped_objects = {}

    # Рисование рамок и группировка результатов
    for class_id, box in zip(classes, boxes):
        class_name = classes_names[int(class_id)]
        color = colors[int(class_id) % len(colors)]  # Выбор цвета для класса
        if class_name not in grouped_objects:
            grouped_objects[class_name] = []
        grouped_objects[class_name].append(box)

        # Рисование рамок на изображении
        x1, y1, x2, y2 = box
        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)
        cv2.putText(image, class_name, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    # Сохранение измененного изображения
    new_image_path = os.path.splitext(image_path)[0] + '_yolo' + os.path.splitext(image_path)[1]
    cv2.imwrite(new_image_path, image)

    # Сохранение данных в текстовый файл
    text_file_path = os.path.splitext(image_path)[0] + '_data.txt'
    with open(text_file_path, 'w') as f:
        for class_name, details in grouped_objects.items():
            f.write(f"{class_name}:\n")
            for detail in details:
                f.write(f"Coordinates: ({detail[0]}, {detail[1]}, {detail[2]}, {detail[3]})\n")

    print(f"Processed {image_path}:")
    print(f"Saved bounding-box image to {new_image_path}")
    print(f"Saved data to {text_file_path}")


process_image('street.png')